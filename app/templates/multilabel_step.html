<ul class="nav nav-tabs">
    <li class="nav-item">
      <a class="nav-link" href="#" id="multilabel_introduction">Introduction</a>
    </li>
    <li class="nav-item">
      <a class="nav-link" href="#" id="multilabel_classifier">Classifier</a>
    </li>
    <li class="nav-item">
      <a class="nav-link" href="#" id="multilabel_infer_time">Infer Time</a>
    </li>
</ul>

<div id="multilabel_introduction_content" class="hidden intro_container">
  <p class="title">Multilabel Step</p>

  <h2 class="space"> Main Objective </h2>  
  <p class='greybox'>
      From the list of pairs, we need to know how much food of each type is consumed.    
  </p>    
  <p class='long_text'>
      For each image of the pair, we can give it a label of food quantity : 
      none / some / many, refering to how much food is there. Note that the segmentation
      step can achieve the same thing by pixel counting. However, using classification
      may achieve a more "human" result, since pixel counting only cares about the area of food,
      and is vulnerable to occlusion.
  </p>

  <h2 class="space"> ResNeXt-101 32x8d </h2>
  <div class="vertical_wrapper center_wrapper">
    <img src='static/images/resnext.png'/>
    <figcaption><a href="https://arxiv.org/abs/1611.05431">
      source: https://arxiv.org/abs/1611.05431
    </a></figcaption>
  </div>
  <p class='long_text'>
    We are using the state-of-the-art ResNeXt-101 32x8d for this classification. 
  </p>

</div>

<div id="multilabel_classifier_content" class="hidden gallery_container">

</div>

<div id="multilabel_infer_time_content" class="hidden">
    <div id="multilabel_infer_time_graph" class="time_chart">
    </div>
</div>